{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMbL-tuJM1EV",
        "outputId": "293619ff-c48c-498e-8fa9-567300f78398"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Natural', 'Language', 'Processing']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "sentence=\"Natural Language Processing\"\n",
        "sentence.split()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"Please, send help\"\n",
        "sentence.split(',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUIuWYOoM-Wq",
        "outputId": "2e8c97ed-070b-432e-aece-51168d383dbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Please', ' send help']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import nltk.corpus"
      ],
      "metadata": {
        "id": "pS76xceINNky"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "from nltk.tokenize import(word_tokenize,TreebankWordTokenizer)\n"
      ],
      "metadata": {
        "id": "fxhi0FT7OZf8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEgNs265Orsz",
        "outputId": "6b0dbdf7-80a9-4d82-fb0d-4dc1e6bca0e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Word Tokenization\n",
        "import nltk\n",
        "word_data=\"Happiness can be found even in the darkest of times, if one remembers to turn on the light\"\n",
        "nltk_tokens=nltk.word_tokenize(word_data)\n",
        "print(nltk_tokens)\n",
        "nltk_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oYBEc5_Ou7H",
        "outputId": "fb4f4207-0924-4351-fdc1-edf0fb8998ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', ',', 'if', 'one', 'remembers', 'to', 'turn', 'on', 'the', 'light']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Happiness',\n",
              " 'can',\n",
              " 'be',\n",
              " 'found',\n",
              " 'even',\n",
              " 'in',\n",
              " 'the',\n",
              " 'darkest',\n",
              " 'of',\n",
              " 'times',\n",
              " ',',\n",
              " 'if',\n",
              " 'one',\n",
              " 'remembers',\n",
              " 'to',\n",
              " 'turn',\n",
              " 'on',\n",
              " 'the',\n",
              " 'light']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(word_data),len(word_data))\n",
        "\n",
        "type(nltk_tokens),len(nltk_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsUJJhaiPiAU",
        "outputId": "d47666d0-134b-4690-f55b-f6e5a8a4fab5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'> 90\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#frequency of tokens\n",
        "from nltk.probability import FreqDist\n",
        "fdist=FreqDist()\n"
      ],
      "metadata": {
        "id": "F0-PJixcQdli"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in nltk_tokens:\n",
        "  fdist[i]=fdist[i]+1\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLFGWxQWQ7a_",
        "outputId": "f5824744-1fb3-4b53-d83d-11365d9db17a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'the': 2, 'Happiness': 1, 'can': 1, 'be': 1, 'found': 1, 'even': 1, 'in': 1, 'darkest': 1, 'of': 1, 'times': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvNCRyy2RAvU",
        "outputId": "2e4792a8-fdc8-4796-bee0-72e8e85de064"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'the': 2, 'Happiness': 1, 'can': 1, 'be': 1, 'found': 1, 'even': 1, 'in': 1, 'darkest': 1, 'of': 1, 'times': 1, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_50=fdist.most_common(50)\n",
        "top_50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLDALRVTRB_y",
        "outputId": "96674005-eeb2-461a-b506-3ad5370bc5e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 2),\n",
              " ('Happiness', 1),\n",
              " ('can', 1),\n",
              " ('be', 1),\n",
              " ('found', 1),\n",
              " ('even', 1),\n",
              " ('in', 1),\n",
              " ('darkest', 1),\n",
              " ('of', 1),\n",
              " ('times', 1),\n",
              " (',', 1),\n",
              " ('if', 1),\n",
              " ('one', 1),\n",
              " ('remembers', 1),\n",
              " ('to', 1),\n",
              " ('turn', 1),\n",
              " ('on', 1),\n",
              " ('light', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Treebankword tokenizer\n",
        "text=\"Happiness can be found even in the darkest of times, if one remembers to turn on the light\"\n",
        "tokenizer=TreebankWordTokenizer()\n",
        "print(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfDLEdpPRrZL",
        "outputId": "1214a065-b665-4d5a-f477-00e22816c1f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', ',', 'if', 'one', 'remembers', 'to', 'turn', 'on', 'the', 'light']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Line Tokenization\n",
        "import nltk\n",
        "sentence_data=\"Happiness can be found even in the darkest of times, if one remembers to turn on the light. It is what it is\"\n",
        "nltk_tokens=nltk.sent_tokenize(sentence_data)\n",
        "print(nltk_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFQlmZy5SFC7",
        "outputId": "377d71bc-f0b2-4378-d767-27e96965e8a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Happiness can be found even in the darkest of times, if one remembers to turn on the light.', 'It is what it is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "german_tokenizer=nltk.data.load('tokenizers/punkt/german.pickle')\n",
        "german_tokens=german_tokenizer.tokenize('Selbst in den dunkelsten Zeiten kann man Glück finden? , wenn man daran denkt, das Licht anzuschalten? ')\n",
        "print(german_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sQlBQh5S41X",
        "outputId": "9214753b-7b33-48e3-a8b2-ae271b82e0b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Selbst in den dunkelsten Zeiten kann man Glück finden?', ', wenn man daran denkt, das Licht anzuschalten?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#character\n",
        "tokens=list(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeU_0kd3T4ml",
        "outputId": "6ed144a8-9e75-4b32-8921-a2c542c1a9c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H', 'a', 'p', 'p', 'i', 'n', 'e', 's', 's', ' ', 'c', 'a', 'n', ' ', 'b', 'e', ' ', 'f', 'o', 'u', 'n', 'd', ' ', 'e', 'v', 'e', 'n', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'd', 'a', 'r', 'k', 'e', 's', 't', ' ', 'o', 'f', ' ', 't', 'i', 'm', 'e', 's', ',', ' ', 'i', 'f', ' ', 'o', 'n', 'e', ' ', 'r', 'e', 'm', 'e', 'm', 'b', 'e', 'r', 's', ' ', 't', 'o', ' ', 't', 'u', 'r', 'n', ' ', 'o', 'n', ' ', 't', 'h', 'e', ' ', 'l', 'i', 'g', 'h', 't']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text.lower()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qZPqPSTaU4A1",
        "outputId": "ce828dab-1dad-4d0c-d311-fe0fde74bd38"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'happiness can be found even in the darkest of times, if one remembers to turn on the light'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lowercased_sentences=[text.lower() for text in sentence_data]\n",
        "print(lowercased_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKa1NL4FVXvu",
        "outputId": "78dc2e67-ee4b-44d0-fad7-f10039cade5d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['h', 'a', 'p', 'p', 'i', 'n', 'e', 's', 's', ' ', 'c', 'a', 'n', ' ', 'b', 'e', ' ', 'f', 'o', 'u', 'n', 'd', ' ', 'e', 'v', 'e', 'n', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'd', 'a', 'r', 'k', 'e', 's', 't', ' ', 'o', 'f', ' ', 't', 'i', 'm', 'e', 's', ',', ' ', 'i', 'f', ' ', 'o', 'n', 'e', ' ', 'r', 'e', 'm', 'e', 'm', 'b', 'e', 'r', 's', ' ', 't', 'o', ' ', 't', 'u', 'r', 'n', ' ', 'o', 'n', ' ', 't', 'h', 'e', ' ', 'l', 'i', 'g', 'h', 't', '.', ' ', 'i', 't', ' ', 'i', 's', ' ', 'w', 'h', 'a', 't', ' ', 'i', 't', ' ', 'i', 's']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text=\"Tokenize is important\"\n",
        "tokens=word_tokenize(text)\n",
        "lowercased=[token.lower()for token in tokens]\n",
        "print(lowercased)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef2p1KUkWKnJ",
        "outputId": "aa349676-caae-4075-9dd2-f40aa4cf0dea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokenize', 'is', 'important']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text=\"This is a Fullstop.next is comma, next is a dollar sign $\"\n",
        "lowercased=re.sub(r'\\b[A-Z]+\\b',lambda match:match.group().lower(), text)\n",
        "lowercased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HBLj5RjQW2vJ",
        "outputId": "9bf640a0-20a1-4fdb-b6de-1cf998bfde96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a Fullstop.next is comma, next is a dollar sign $'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "text=\"This is a Fullstop. next is comma, next is a dollar sign $\"\n",
        "print(nltk.wordpunct_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM8hSP4yXdBN",
        "outputId": "b50c9d62-29de-4e70-92c5-df0a6d7179f3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'Fullstop', '.', 'next', 'is', 'comma', ',', 'next', 'is', 'a', 'dollar', 'sign', '$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=TreebankWordTokenizer()\n",
        "print(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hU7_u_Adlyr",
        "outputId": "d56612ed-6990-4dbb-9f7a-47ca0ed743b2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'Fullstop.', 'next', 'is', 'comma', ',', 'next', 'is', 'a', 'dollar', 'sign', '$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus.reader.twitter import TweetTokenizer\n",
        "text=\"Happiness can be found even in the darkest of times 😀😀😀\"\n",
        "print(tokenizer.tokenize(text))\n",
        "tweet=TweetTokenizer()\n",
        "print(tweet.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrgyH6iyewNm",
        "outputId": "e7c31f6c-642b-4966-e571-3ad24b6e35b5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', '😀😀😀']\n",
            "['Happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', '😀', '😀', '😀']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import (word_tokenize, sent_tokenize, TreebankWordTokenizer, wordpunct_tokenize, MWETokenizer)"
      ],
      "metadata": {
        "id": "EwjmulgUfQV7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# import MWETokenizer() method from nltk\n",
        "from nltk.tokenize import MWETokenizer\n",
        "text=\"happiness can be found even in the darkest of times. Hunger Games $$ Harry\"\n",
        "tokenizer=MWETokenizer()\n",
        "print(tokenizer.tokenize(word_tokenize(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwwHWxBbgWCp",
        "outputId": "ff9221cd-2678-4ee4-b6ef-f0b76e4c8b0c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', '.', 'Hunger', 'Games', '$', '$', 'Harry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.add_mwe(('Hunger', 'Games'))\n",
        "print(tokenizer.tokenize(word_tokenize(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0VsDeLEgoah",
        "outputId": "d3867597-dac5-4d24-8485-d9cf35e09e27"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', '.', 'Hunger_Games', '$', '$', 'Harry']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "text=\"happiness can be found even in the darkest of times. 😀 😀 😀\"\n",
        "blob_object=TextBlob(text)\n",
        "text_words=blob_object.words\n",
        "print(text_words)\n",
        "print(len(text_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueY079mahh_l",
        "outputId": "9e1f3808-8e81-4d36-9d21-a392805097c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', '😀', '😀', '😀']\n",
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=\"happiness can be found even in the darkest of times. 😀 😀 😀 U.S.A\"\n",
        "doc= nlp(text)\n",
        "for token in doc:\n",
        "  print(token, token.idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8-cW4Pzih7M",
        "outputId": "9ae48271-484d-41df-f983-2837985b16bc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happiness 0\n",
            "can 10\n",
            "be 14\n",
            "found 17\n",
            "even 23\n",
            "in 28\n",
            "the 31\n",
            "darkest 35\n",
            "of 43\n",
            "times 46\n",
            ". 51\n",
            "😀 53\n",
            "😀 55\n",
            "😀 57\n",
            "U.S.A 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "ntoken= Tokenizer(num_words=20)"
      ],
      "metadata": {
        "id": "tCyGWHUpjROG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"happiness can be found even in the darkest of times... 😀 😀 😀\"\n",
        "ntoken.fit_on_texts(text)\n",
        "list_words=text_to_word_sequence(text)\n",
        "print(list_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL37Uq0ok-cW",
        "outputId": "2f709aad-19d5-41f1-fb5b-1520d5f32354"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happiness', 'can', 'be', 'found', 'even', 'in', 'the', 'darkest', 'of', 'times', '😀', '😀', '😀']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"happiness can be found even; in the darkest of times.\"\n",
        "example=word_tokenize(text)\n",
        "example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdysUil3lQDP",
        "outputId": "a4bf59c7-89d2-4296-e465-9496cd84d6c9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['happiness',\n",
              " 'can',\n",
              " 'be',\n",
              " 'found',\n",
              " 'even',\n",
              " ';',\n",
              " 'in',\n",
              " 'the',\n",
              " 'darkest',\n",
              " 'of',\n",
              " 'times',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.bigrams(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuO8ND91ntSt",
        "outputId": "41937d50-45fa-4659-8589-d9eb242df9ab"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('happiness', 'can'),\n",
              " ('can', 'be'),\n",
              " ('be', 'found'),\n",
              " ('found', 'even'),\n",
              " ('even', ';'),\n",
              " (';', 'in'),\n",
              " ('in', 'the'),\n",
              " ('the', 'darkest'),\n",
              " ('darkest', 'of'),\n",
              " ('of', 'times'),\n",
              " ('times', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.trigrams(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Je8jiltoEuC",
        "outputId": "f9b062e2-1107-44f7-b080-5119f41b24c7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('happiness', 'can', 'be'),\n",
              " ('can', 'be', 'found'),\n",
              " ('be', 'found', 'even'),\n",
              " ('found', 'even', ';'),\n",
              " ('even', ';', 'in'),\n",
              " (';', 'in', 'the'),\n",
              " ('in', 'the', 'darkest'),\n",
              " ('the', 'darkest', 'of'),\n",
              " ('darkest', 'of', 'times'),\n",
              " ('of', 'times', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(nltk.ngrams(example,12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTatMUOLoO_9",
        "outputId": "05cb88df-6f54-438d-926b-13946b442577"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('happiness',\n",
              "  'can',\n",
              "  'be',\n",
              "  'found',\n",
              "  'even',\n",
              "  ';',\n",
              "  'in',\n",
              "  'the',\n",
              "  'darkest',\n",
              "  'of',\n",
              "  'times',\n",
              "  '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "import nltk\n",
        "from nltk.stem.porter import *\n",
        "pst=PorterStemmer()"
      ],
      "metadata": {
        "id": "dTIEqxOgogUG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pst.stem(\"winning\"),pst.stem(\"this\"),pst.stem(\"buying\"),pst.stem(\"mosses\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3-Bi2WVq4-x",
        "outputId": "1573a885-912e-410e-f446-63835ea7fea1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('win', 'thi', 'buy', 'moss')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_stemmer=PorterStemmer()\n",
        "words=['run','runner','running','runs', 'easily','fairly','cognitive', 'rational']\n",
        "for word in words:\n",
        "  print(word+'-->'+p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4EFQieWrTsK",
        "outputId": "49af6659-008e-4b68-b52d-6c244d4efa0e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run-->run\n",
            "runner-->runner\n",
            "running-->run\n",
            "runs-->run\n",
            "easily-->easili\n",
            "fairly-->fairli\n",
            "cognitive-->cognit\n",
            "rational-->ration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "s_stemmer=SnowballStemmer(language='english')\n",
        "words=['run','runner','running','runs', 'easily','fairly','cognitive', 'rational','generously']\n",
        "for word in words:\n",
        "  print(word+'-->'+s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCE8LHIHsNPT",
        "outputId": "8764156f-fef5-4c9a-dd3f-3d28e849d4f1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run-->run\n",
            "runner-->runner\n",
            "running-->run\n",
            "runs-->run\n",
            "easily-->easili\n",
            "fairly-->fair\n",
            "cognitive-->cognit\n",
            "rational-->ration\n",
            "generously-->generous\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"happiness can be found even; in the darkest of times .\"\n",
        "for word in text.split():\n",
        "  print(word+'-->'+s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En_0Yn8fto1h",
        "outputId": "cd9564da-ad20-4b14-f97a-dd9dbec79fed"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happiness-->happi\n",
            "can-->can\n",
            "be-->be\n",
            "found-->found\n",
            "even;-->even;\n",
            "in-->in\n",
            "the-->the\n",
            "darkest-->darkest\n",
            "of-->of\n",
            "times-->time\n",
            ".-->.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRWdx_rjub63",
        "outputId": "93e4c030-1ca1-48a2-b21c-787b3319ff0c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "words_to_stem=[\"cats\",\"saw\",\"cacti\",\"easily\", \"studying\"]"
      ],
      "metadata": {
        "id": "04Lk7xjq9Ubx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words_to_stem:\n",
        "  print(word+'-->'+lemmatizer.lemmatize(word))\n",
        "  #keras and textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSuTeA-t91NC",
        "outputId": "366077ab-4e42-410f-a939-c334f6766daf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats-->cat\n",
            "saw-->saw\n",
            "cacti-->cactus\n",
            "easily-->easily\n",
            "studying-->studying\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=\"study studying studied easily\"\n",
        "doc=nlp(text)\n",
        "lemmatized_tokens=[token.lemma_ for token in doc]"
      ],
      "metadata": {
        "id": "nWD3pjW6-Epy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3v4804J_Dfj",
        "outputId": "d93484e4-96ea-4bae-f744-3a9ae6b6e14c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['study', 'studying', 'study', 'easily']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "words=\"study studying studied easily\"\n",
        "lemmatized_tokens=[Word(word).lemmatize() for word in words.split()]\n",
        "print(lemmatized_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z8t6QKo_Ggf",
        "outputId": "2c048468-3b33-4db3-ab93-4159d4eee6a0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['study', 'studying', 'studied', 'easily']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print(len(stopwords.words('english')))\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-L6fPVH_8Qr",
        "outputId": "08be0269-2636-438d-9cd5-afa8c133c8a5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Happiness can be found even in the darkest of times, if one remembers to turn on the light\"\n",
        "tokens=word_tokenize(text)\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "filtered_tokens=[token for token in tokens if token.lower() not in stop_words]\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13cmDHmuAvLb",
        "outputId": "cf369f70-1805-405b-a0c7-74127d717b55"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Happiness', 'found', 'even', 'darkest', 'times', ',', 'one', 'remembers', 'turn', 'light']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['my'].is_stop #we can also add our names as stop words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLyDLF9QBr_y",
        "outputId": "87994695-27ee-4321-a45f-d75884417899"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.add('mystery')"
      ],
      "metadata": {
        "id": "B5RPR7YdC8UO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.vocab['mystery'].is_stop\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKDK0YtADKLK",
        "outputId": "9f698f42-6919-44d6-fa69-ae5471b40101"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=stopwords.words('english')\n",
        "print(len(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPJRHzMKDOxJ",
        "outputId": "f3ad856a-3c9e-421d-a768-230f72aba4d8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp3z8xDKDYsZ",
        "outputId": "7568ca98-360e-4cbc-959c-98c5413778cc"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.Defaults.stop_words.remove('my')"
      ],
      "metadata": {
        "id": "KvoB2b25D30q"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg=\"What is that, for a second I thought it was a man sitting, turns out to be an umbrella\"\n",
        "nltk.download('averaged_percerptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1Ah15gvEHbF",
        "outputId": "ff3eee2c-72db-4516-ca33-59beb2695f40"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Error loading averaged_percerptron_tagger: Package\n",
            "[nltk_data]     'averaged_percerptron_tagger' not found in index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjQCVdqqHV8O",
        "outputId": "fd789dc1-78d9-44b0-817e-ad24f5c28273"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qiWBdiaHZr0",
        "outputId": "65cd5d06-5bd6-408a-a36e-3889a7686e57"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msg_tokens=word_tokenize(msg)\n",
        "msg_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjq1bNl1HhYi",
        "outputId": "79d10a46-12c9-4c43-a760-cc66cd484158"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What',\n",
              " 'is',\n",
              " 'that',\n",
              " ',',\n",
              " 'for',\n",
              " 'a',\n",
              " 'second',\n",
              " 'I',\n",
              " 'thought',\n",
              " 'it',\n",
              " 'was',\n",
              " 'a',\n",
              " 'man',\n",
              " 'sitting',\n",
              " ',',\n",
              " 'turns',\n",
              " 'out',\n",
              " 'to',\n",
              " 'be',\n",
              " 'an',\n",
              " 'umbrella']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in msg_tokens:\n",
        "  print(nltk.pos_tag([i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA03ZWAmHtqr",
        "outputId": "18e0e9cd-3790-4b3f-a043-b4f42090e7fb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('What', 'WP')]\n",
            "[('is', 'VBZ')]\n",
            "[('that', 'IN')]\n",
            "[(',', ',')]\n",
            "[('for', 'IN')]\n",
            "[('a', 'DT')]\n",
            "[('second', 'JJ')]\n",
            "[('I', 'PRP')]\n",
            "[('thought', 'NN')]\n",
            "[('it', 'PRP')]\n",
            "[('was', 'VBD')]\n",
            "[('a', 'DT')]\n",
            "[('man', 'NN')]\n",
            "[('sitting', 'VBG')]\n",
            "[(',', ',')]\n",
            "[('turns', 'NNS')]\n",
            "[('out', 'IN')]\n",
            "[('to', 'TO')]\n",
            "[('be', 'VB')]\n",
            "[('an', 'DT')]\n",
            "[('umbrella', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in msg_tokens:\n",
        "    pos_tags = nltk.pos_tag([token])\n",
        "    for tag in pos_tags:\n",
        "        print(tag[0], nltk.help.upenn_tagset(tag[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8ZXuKYDIcZM",
        "outputId": "8b7c7b1c-e007-4273-e56d-d00c9542f06d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "What None\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "is None\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "that None\n",
            ",: comma\n",
            "    ,\n",
            ", None\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "for None\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "a None\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "second None\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "I None\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "thought None\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "it None\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "was None\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "a None\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "man None\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "sitting None\n",
            ",: comma\n",
            "    ,\n",
            ", None\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "turns None\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "out None\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "to None\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "be None\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "an None\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "umbrella None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "text=\"POS tagging is important for NLP tasks\"\n",
        "doc=nlp(text)\n",
        "pos_tags=[(token.text,token.pos_)for token in doc]\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZLqlNsiIceq",
        "outputId": "02db9a7e-5f2a-4198-e8e6-348f90b2364f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('POS', 'PROPN'), ('tagging', 'NOUN'), ('is', 'AUX'), ('important', 'ADJ'), ('for', 'ADP'), ('NLP', 'PROPN'), ('tasks', 'NOUN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token,\"|\",token.lemma_, \"|\", token.pos_,\"|\", spacy.explain(token),\"|\",token.tag_,spacy.explain(token.tag_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgSWKqThH3D3",
        "outputId": "ff69796b-4c77-418f-d64c-75a1bdd29769"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS | POS | PROPN | None | NNP noun, proper singular\n",
            "tagging | tagging | NOUN | None | NN noun, singular or mass\n",
            "is | be | AUX | None | VBZ verb, 3rd person singular present\n",
            "important | important | ADJ | None | JJ adjective (English), other noun-modifier (Chinese)\n",
            "for | for | ADP | None | IN conjunction, subordinating or preposition\n",
            "NLP | NLP | PROPN | None | NNP noun, proper singular\n",
            "tasks | task | NOUN | None | NNS noun, plural\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "sentence=\"I am learning nlp in Python\"\n",
        "tokens=nltk.word_tokenize(sentence)\n",
        "pos_tags=nltk.pos_tag(tokens)\n",
        "print(pos_tags)\n",
        "for token in sentence.split():\n",
        "    pos_tags = nltk.pos_tag([token])\n",
        "    for tag in pos_tags:\n",
        "        print(tag[0], nltk.help.upenn_tagset(tag[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCoT-02fJX3b",
        "outputId": "769d376c-e8a9-44fb-aecc-7192474243f4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRP'), ('am', 'VBP'), ('learning', 'VBG'), ('nlp', 'NN'), ('in', 'IN'), ('Python', 'NNP')]\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "I None\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "am None\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "learning None\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "nlp None\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "in None\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "Python None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('tagsets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hGp2jg2MDXt",
        "outputId": "572e3826-601c-4e7e-c84a-2755cc48336b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Named Entity Recognition(NER)\n",
        "from nltk import ne_chunk\n",
        "nltk.download('maxent_ne_chunker')# chunking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FqD92uSMh42",
        "outputId": "4b273131-7f74-49ef-b8bd-c15d3d3aa216"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UBr7PxBRc-Q",
        "outputId": "be0296d6-f1d1-461d-e1a9-c38e9e249e90"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"I am learning NLP\"\n",
        "text_token=word_tokenize(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r4qxS7mZRw-P",
        "outputId": "785e592f-f433-48d1-beaf-dba0da12e5ee"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am learning NLP'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_tags=nltk.pos_tag(text_token)\n",
        "text_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx6tZnz6SJTF",
        "outputId": "748dd7b7-cc23-41ea-b9e5-4ea10a55976e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'), ('am', 'VBP'), ('learning', 'VBG'), ('NLP', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_NER=ne_chunk(text_tags)\n",
        "print(text_NER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ3sGjamSPln",
        "outputId": "9f4b7993-9229-4883-ab34-bab67d99269f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S I/PRP am/VBP learning/VBG (ORGANIZATION NLP/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "sentence=\"Elon Musk has been instrumental in several groundbreaking ventures. SpaceX, founded in 2002, aims to revolutionize space technology and make space travel more accessible. Tesla, Inc., established in 2003, focuses on electric vehicles and sustainable energy solutions. Neuralink, founded in 2016, explores the development of implantable brain-machine interfaces. The Boring Company, founded in 2016, aims to create advanced tunneling and infrastructure solutions to alleviate traffic congestion.\"\n",
        "doc=nlp(sentence)\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,\"-\",ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFmOleghSlax",
        "outputId": "e89a79c5-dffe-4364-8001-c7fb827932fb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk - PERSON\n",
            "2002 - DATE\n",
            "Tesla, Inc. - ORG\n",
            "2003 - DATE\n",
            "2016 - DATE\n",
            "The Boring Company - ORG\n",
            "2016 - DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "doc=nlp(u'Apple is going to build a U.K. factory for 1 Billion. Apple is a company')#u unicode characters\n",
        "displacy.render(doc,style='dep', jupyter=True, options={'distance':110})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "GJogrljPT1tE",
        "outputId": "a5027229-e3c9-4be5-a59c-04f0a60f9dc1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a06e60f991a64331a4cb601ed5665911-0\" class=\"displacy\" width=\"1700\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">1</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">Billion.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1480\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1480\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">company</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,167.0 1135.0,167.0 1135.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-9\" stroke-width=\"2px\" d=\"M950,222.0 C950,112.0 1140.0,112.0 1140.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1140.0,224.0 L1148.0,212.0 1132.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-10\" stroke-width=\"2px\" d=\"M1280,222.0 C1280,167.0 1355.0,167.0 1355.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1280,224.0 L1272,212.0 1288,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-11\" stroke-width=\"2px\" d=\"M1500,222.0 C1500,167.0 1575.0,167.0 1575.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1500,224.0 L1492,212.0 1508,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a06e60f991a64331a4cb601ed5665911-0-12\" stroke-width=\"2px\" d=\"M1390,222.0 C1390,112.0 1580.0,112.0 1580.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a06e60f991a64331a4cb601ed5665911-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1580.0,224.0 L1588.0,212.0 1572.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc,style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "02FwpESLVhMH",
        "outputId": "18be1c28-91ce-4623-9db6-b965c4f8b7d9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is going to build a \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " factory for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1 Billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is a company</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Id9WKz5UWeHH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}