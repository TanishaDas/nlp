{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci4mQH3f0ncl",
        "outputId": "fb84443d-6a09-47a4-8d32-8bb31c88d5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aHxg0Abe2Bl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT3_SECRET_KEY=\"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\"\n",
        "openai.api_key=GPT3_SECRET_KEY"
      ],
      "metadata": {
        "id": "viuZbciN3Nr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to OpenAI"
      ],
      "metadata": {
        "id": "rTbhOmpY3gqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_prompt(prompt,max_tokens):\n",
        "  return openai.Completion.create(\n",
        "      model=\"text-davinci-002\",\n",
        "      prompt=prompt,\n",
        "      temperature=0, #controls the randomness\n",
        "      max_tokens=max_tokens,\n",
        "      top_p=1.0,\n",
        "      frequency_penalty=0.0, #dont want repeatation of more words\n",
        "      presence_penalty=0.0\n",
        "  )"
      ],
      "metadata": {
        "id": "c-rOkax_4VRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'A table summarizing the fruits from Goocrux:\\n\\\n",
        "    There are many fruits tat were found on the recently discovered planet Goocrux .\\n\\\n",
        "        There are neoskizzles that grow there, which are purple and tast like candy.\\n\\\n",
        "            there are also loheckles, whcih are a grayish blue fruit and are very tart,\\\\n\\\n",
        "            a little bit like a lemon, Pounits are bright green color and are more savory than sweet .\\n\\\n",
        "                there are also plenty of oopnovas which are neon pink flavor and taste like cotton candy . \\n\\\n",
        "                    Finally there are fruits called glowls, which have a very sour and \\n\\\n",
        "                        bitter taaste which is acidic and caustic,\\n\\\n",
        "                            \\and a pale orange tinge to them.\\n\\\n",
        "                            \\n| Fruit | Color |Flavor |'\n",
        "response =submit_prompt(prompt,max_tokens=100)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96j3lBja5wZN",
        "outputId": "1faec591-f4f6-41dc-da79-762d698c1f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "| Neoskizzles | Purple | Candy |\n",
            "| Loheckles | Grayish-blue | Tart |\n",
            "| Pounits | Bright green | Savory |\n",
            "| Oopnovas | Neon pink | Cotton candy |\n",
            "| Glowls | Pale orange | Sour and bitter |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classify items into category via example"
      ],
      "metadata": {
        "id": "3Skmm6bo7mK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"The following is a list of companies and the categories they fall into:\\n\\\n",
        "Amul,Nayara,Relaince\\n\\n\\\n",
        "Company:\\n\\\n",
        "Category:\"\n",
        "\n",
        "response=submit_prompt(prompt,max_tokens=64)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggh3pjLc85ze",
        "outputId": "d1809c06-35fc-41ca-bf15-c3c94b9d55cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Amul: Dairy\n",
            "Nayara: Oil and Gas\n",
            "Reliance: Conglomerate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\" #### Translate this function from python to Cpp\\n\\\n",
        "### Python\\n\\\n",
        "      def multiply(a,b):\\n\\\n",
        "        return a*b \\n\\\n",
        "        \\n\\n\\\n",
        "      #### Cpp\\\n",
        "      \"\n",
        "response=submit_prompt(prompt,max_tokens=64)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmWSdooO9mt6",
        "outputId": "fbdab396-2e0c-446e-b956-6c3e65bb3de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      int multiply(int a, int b) {\n",
            "        return a*b;\n",
            "      }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"def foo(n,k):\n",
        "accum = 0\n",
        "for i in range(n):\n",
        "    accum+=i\n",
        "return accum\n",
        "the time complexity of the abve function is\"\"\"\n",
        "response= submit_prompt(prompt,max_tokens=64)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWndGVxk-1TN",
        "outputId": "5a35799a-4783-4716-dbde-cfa0289fcf9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " O(n)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SQL example"
      ],
      "metadata": {
        "id": "_0Pv12ZcCQwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Create a SQL request to find all users who live in california and have over 1000 credits:\"\n",
        "response=submit_prompt(prompt,max_tokens=64)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPgTCe2w_O6s",
        "outputId": "69136925-7d8d-499b-ff42-960754f12daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "SELECT * FROM users WHERE state = 'California' AND credits > 1000;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"Fix bugs in the below function\\n\\\n",
        "Buggy Python \\n\\\n",
        "import random\\n\\\n",
        "a=random.randint(1,12)\n",
        "b=random.randint(1,12)\n",
        "for i in range[10]\n",
        "question=\"WHat is +a* x +b+\"\n",
        "answer=input(question)\n",
        "\n",
        "#### fiz the code\n",
        "\"\"\"\n",
        "response=submit_prompt(prompt,max_tokens=64)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vwyTWSYCAg7",
        "outputId": "c018960c-ce2e-47fd-bb70-3a6feb24122f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "import random\n",
            "\n",
            "a = random.randint(1, 12)\n",
            "b = random.randint(1, 12)\n",
            "\n",
            "for i in range(10):\n",
            "    question = \"What is \" + str(a) + \" x \" + str(b) + \"?\"\n",
            "   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What is a language model?\\n\\\n",
        "\"\n",
        "response=submit_prompt(prompt,max_tokens=64)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ameN0wTvDKKv",
        "outputId": "e0f46795-a5b1-45e3-ee98-7755c272bb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A language model is a statistical model that is used to predict the probability of a sequence of words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"convert my short hand into a first hand account of the meeting:\\n\\\n",
        "tom:profits up 50%\\n\\n\\\n",
        "jane:New servers are online\\n\\n\\\n",
        "kyle:need more time to fix software\\n\\n\\\n",
        "jane:happy to help\\n\\n\\\n",
        "PArkman:Thanks for the feedback\\n\\n\\\n",
        "\"\n",
        "response=submit_prompt(prompt,max_tokens=64)\n",
        "print(response.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8IS4ElRDLye",
        "outputId": "9c99c710-8b45-4768-e3f3-921ff9dd3528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tom said that profits were up 50%. Jane said that new servers were online. Kyle said that he needed more time to fix the software. Jane said that she was happy to help. Parkman said that he was thanks for the feedback.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "def set_openai_key(key):\n",
        "    \"\"\"Sets OpenAI key.\"\"\"\n",
        "    openai.api_key = key\n",
        "\n",
        "class Example():\n",
        "    \"\"\"Stores an input, output pair and formats it to prime the model.\"\"\"\n",
        "\n",
        "    def __init__(self, inp, out):\n",
        "        self.input = inp\n",
        "        self.output = out\n",
        "\n",
        "    def get_input(self):\n",
        "        \"\"\"Returns the input of the example.\"\"\"\n",
        "        return self.input\n",
        "\n",
        "    def get_output(self):\n",
        "        \"\"\"Returns the intended output of the example.\"\"\"\n",
        "        return self.output\n",
        "\n",
        "    def format(self):\n",
        "        \"\"\"Formats the input, output pair.\"\"\"\n",
        "        return f\"input: {self.input}\\noutput: {self.output}\\n\"\n",
        "\n",
        "\n",
        "class GPT:\n",
        "    \"\"\"The main class for a user to interface with the OpenAI API.\n",
        "    A user can add examples and set parameters of the API request.\"\"\"\n",
        "\n",
        "    def __init__(self, engine='davinci-002',\n",
        "                 temperature=0.5,\n",
        "                 max_tokens=100):\n",
        "        self.examples = []\n",
        "        self.engine = engine\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def add_example(self, ex):\n",
        "        \"\"\"Adds an example to the object. Example must be an instance\n",
        "        of the Example class.\"\"\"\n",
        "        assert isinstance(ex, Example), \"Please create an Example object.\"\n",
        "        self.examples.append(ex.format())\n",
        "\n",
        "    def get_prime_text(self):\n",
        "        \"\"\"Formats all examples to prime the model.\"\"\"\n",
        "        return '\\n'.join(self.examples) + '\\n'\n",
        "\n",
        "    def get_engine(self):\n",
        "        \"\"\"Returns the engine specified for the API.\"\"\"\n",
        "        return self.engine\n",
        "\n",
        "    def get_temperature(self):\n",
        "        \"\"\"Returns the temperature specified for the API.\"\"\"\n",
        "        return self.temperature\n",
        "\n",
        "    def get_max_tokens(self):\n",
        "        \"\"\"Returns the max tokens specified for the API.\"\"\"\n",
        "        return self.max_tokens\n",
        "\n",
        "    def craft_query(self, prompt):\n",
        "        \"\"\"Creates the query for the API request.\"\"\"\n",
        "        return self.get_prime_text() + \"input: \" + prompt + \"\\n\"\n",
        "\n",
        "    def submit_request(self, prompt):\n",
        "        \"\"\"Calls the OpenAI API with the specified parameters.\"\"\"\n",
        "        response = openai.Completion.create(engine=self.get_engine(),\n",
        "                                            prompt=self.craft_query(prompt),\n",
        "                                            max_tokens=self.get_max_tokens(),\n",
        "                                            temperature=self.get_temperature(),\n",
        "                                            top_p=1,\n",
        "                                            n=1,\n",
        "                                            stream=False,\n",
        "                                            stop=\"\\ninput:\")\n",
        "        return response\n",
        "\n",
        "    def get_top_reply(self, prompt):\n",
        "        \"\"\"Obtains the best result as returned by the API.\"\"\"\n",
        "        response = self.submit_request(prompt)\n",
        "        return response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "evH7jls4Ec8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame({\n",
        "    \"Gender\":[\"boy\", \"boy\",\"boy\",\"boy\",\"boy\",\"girl\",\"girl\",\"girl\",\"girl\",\"girl\"],\n",
        "    \"Section\":[\"A\",\"B\",\"A\",\"B\",\"A\",\"B\",\"A\",\"B\",\"A\",\"B\"],\n",
        "    \"Marks\":[50,55,67,85,98,44,23,42,65,65]\n",
        "})"
      ],
      "metadata": {
        "id": "aJaQbmGYKigv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt=GPT(engine=\"text-davinci-002\",\n",
        "        temperature=0.5,\n",
        "        max_tokens=100)"
      ],
      "metadata": {
        "id": "KinPAx8uMs7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=gpt.submit_request('How many unique values in section column?')\n",
        "print(res.choices[0].text)"
      ],
      "metadata": {
        "id": "5d4Vkx_QNhJQ",
        "outputId": "46c74996-e34d-4cc6-ba3e-f081638109d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "There are 3 unique values in the section column.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Find the median Marks scored by boys\"\n",
        "print(gpt.get_top_reply(prompt))"
      ],
      "metadata": {
        "id": "HOOMZboaNn-l",
        "outputId": "43086492-4e0d-4895-95ab-9d6b4426eaf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "output:\n",
            "\n",
            "The median score for boys is 80.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.median(df.loc[(df.loc[:,\"Gender\"]==\"boy\"),\"Marks\"])"
      ],
      "metadata": {
        "id": "b8HwbidaQGEn",
        "outputId": "b97894a7-dadd-43e3-8beb-4e8505106f84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.add_example(Example('Plot Scatter Plot between Section A marks & Section B marks',\n",
        "                        'plt.scatter(df[df[\"Section\"] == \"A\"][\"Marks\"], df[df[\"Section\"] == \"B\"][\"Marks\"]'))\n",
        "\n",
        "gpt.add_example(Example('Plot Bar Plot of Gender',\n",
        "                        \"sns.countplot('Gender',data=df)\"))\n",
        "\n",
        "gpt.add_example(Example('Plot Bar Plot of Boys',\n",
        "                        'sns.countplot(data = df[df[\"Gender\"] == \"boy\"], x = \"Section\")'))\n",
        "\n",
        "gpt.add_example(Example('Show me the histogram of Marks',\n",
        "                        \"plt.hist(df['Marks'])\"))"
      ],
      "metadata": {
        "id": "JeLauE7cOf3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"show me the scatter plot between Boys marks and Girls Marks\"\n",
        "response=gpt.get_top_reply(prompt)\n",
        "print(response)\n",
        "modified_response=response.split(\"output: \")[-1].strip('\\n')"
      ],
      "metadata": {
        "id": "znTifZ__Pvo_",
        "outputId": "8d0b5ccf-513a-43f0-f44b-2110785f46c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: plt.scatter(df[df[\"Gender\"] == \"boy\"][\"Marks\"], df[df[\"Gender\"] == \"girl\"][\"Marks\"])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df[df[\"Gender\"] == \"boy\"][\"Marks\"], df[df[\"Gender\"] == \"girl\"][\"Marks\"])"
      ],
      "metadata": {
        "id": "JKJo3fw3STYc",
        "outputId": "b20b1e3c-6268-4ad3-bd68-6e0d63268c65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x78a81367bac0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nluN0r42SVsv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}